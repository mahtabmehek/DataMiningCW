{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dRDkeT1vvAzs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from helper import get_my_dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import create_my_dataset_csv, MY_LOCAL_AUTHORITY_HIGHWAY\n",
    "create_my_dataset_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the data_set filtered for my borough\n",
    "\"\"\"\n",
    "main_df = get_my_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Checking the rows and columns of the dataset\n",
    "\"\"\"\n",
    "main_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Checking missing values\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "missing_indicators = [-1, \"-1\", \"\"]\n",
    "\n",
    "missing_values = main_df.isnull().sum()\n",
    "for col in main_df.columns:\n",
    "    missing_values[col] += (main_df[col].isin(missing_indicators)).sum()\n",
    "\n",
    "print(\"Missing Values Per Column:\")\n",
    "print(missing_values)\n",
    "\n",
    "sns.heatmap(main_df.isin(missing_indicators) | main_df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Missing Data Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize to see distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "numerical_columns = [\n",
    "    'Number_of_Vehicles', 'Number_of_Casualties'\n",
    "]\n",
    "\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(main_df[column], kde=True, color='blue')\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(main_df[column], orient='h', color='skyblue')\n",
    "    plt.title(f'Boxplot of {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for column in numerical_columns:\n",
    "    Q1 = main_df[column].quantile(0.25)\n",
    "    Q3 = main_df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = main_df[(main_df[column] < lower_bound) | (main_df[column] > upper_bound)]\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.boxplot(x=main_df[column], color='lightblue', showfliers=False)  \n",
    "    plt.scatter(outliers[column], [0] * len(outliers), color='red', label='Outliers')  \n",
    "    plt.title(f'Boxplot of {column} with Highlighted Outliers')\n",
    "    plt.xlabel(column)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_extreme_values(df, numerical_columns):\n",
    "    for column in numerical_columns:\n",
    "\n",
    "        low_percentile = df[column].quantile(0.01)\n",
    "        high_percentile = df[column].quantile(0.99)\n",
    "        \n",
    "        extreme_values = df[(df[column] < low_percentile) | (df[column] > high_percentile)]\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(data=df[column], color='lightblue', showfliers=False)  # Boxplot without default outliers\n",
    "        plt.scatter(extreme_values[column], [0] * len(extreme_values), color='orange', label='Extreme Values')  # Highlight extreme values\n",
    "        plt.title(f'Boxplot of {column} with Highlighted Extreme Values')\n",
    "        plt.xlabel(column)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "numerical_columns = ['Number_of_Vehicles', 'Number_of_Casualties']\n",
    "\n",
    "plot_extreme_values(main_df, numerical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incomparable value ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Number_of_Vehicles', 'Number_of_Casualties']\n",
    "\n",
    "print(\"Value Ranges for Numerical Columns:\")\n",
    "for column in numerical_columns:\n",
    "    min_val = main_df[column].min()\n",
    "    max_val = main_df[column].max()\n",
    "    range_val = max_val - min_val\n",
    "    print(f\"{column}: Min = {min_val}, Max = {max_val}, Range = {range_val}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ranges = {column: main_df[column].max() - main_df[column].min() for column in numerical_columns}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(ranges.keys(), ranges.values(), color='skyblue')\n",
    "plt.title('Range of Values for Numerical Columns')\n",
    "plt.ylabel('Range')\n",
    "plt.xlabel('Columns')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"Police_Force\",\n",
    "    \"Accident_Severity\",\n",
    "    \"Number_of_Vehicles\",\n",
    "    \"Number_of_Casualties\",\n",
    "    \"Day_of_Week\",\n",
    "    \"Local_Authority_District\",\n",
    "    \"Local_Authority_Highway\",\n",
    "    \"1st_Road_Class\",\n",
    "    \"1st_Road_Number\",\n",
    "    \"Road_Type\",\n",
    "    \"Speed_limit\",\n",
    "    \"Junction_Detail\",\n",
    "    \"Junction_Control\",\n",
    "    \"2nd_Road_Class\",\n",
    "    \"2nd_Road_Number\",\n",
    "    \"Pedestrian_Crossing-Human_Control\",\n",
    "    \"Pedestrian_Crossing-Physical_Facilities\",\n",
    "    \"Light_Conditions\",\n",
    "    \"Weather_Conditions\",\n",
    "    \"Road_Surface_Conditions\",\n",
    "    \"Special_Conditions_at_Site\",\n",
    "    \"Carriageway_Hazards\",\n",
    "    \"Urban_or_Rural_Area\",\n",
    "    \"Did_Police_Officer_Attend_Scene_of_Accident\",\n",
    "]\n",
    "\n",
    "print(\"Class Distributions for Categorical Columns:\")\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\n{column} Distribution:\")\n",
    "    print(main_df[column].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    sns.countplot(\n",
    "        data=main_df,\n",
    "        x=column,\n",
    "        order=main_df[column].value_counts().index,\n",
    "        color='skyblue',\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapped version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_df['Date'] = pd.to_datetime(main_df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "main_df['Time'] = pd.to_datetime(main_df['Time'], format='%H:%M', errors='coerce')\n",
    "\n",
    "category_columns = [\n",
    "    'Police_Force', 'Accident_Severity', 'Day_of_Week', 'Speed_limit', 'Weather_Conditions',\n",
    "    'Road_Type', 'Light_Conditions', 'Urban_or_Rural_Area', '1st_Road_Class', '1st_Road_Number',\n",
    "    '2nd_Road_Class', '2nd_Road_Number', 'Local_Authority_Highway', 'Junction_Detail',\n",
    "    'Junction_Control', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities',\n",
    "    'Road_Surface_Conditions', 'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
    "    'Did_Police_Officer_Attend_Scene_of_Accident', 'Local_Authority_District'\n",
    "]\n",
    "\n",
    "int_columns = ['Number_of_Vehicles', 'Number_of_Casualties']\n",
    "\n",
    "\n",
    "for col in category_columns:\n",
    "    main_df[col] = main_df[col].astype('category')\n",
    "\n",
    "for col in int_columns:\n",
    "    main_df[col] = main_df[col].astype(int)\n",
    "\n",
    "main_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic statistics of each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "numerical_columns = ['Location_Easting_OSGR', 'Location_Northing_OSGR', \n",
    "                     'Longitude', 'Latitude', \n",
    "                     'Number_of_Vehicles', 'Number_of_Casualties']\n",
    "\n",
    "categorical_columns = [\n",
    "        'Police_Force', 'Accident_Severity', 'Day_of_Week', 'Speed_limit', 'Weather_Conditions',\n",
    "    'Road_Type', 'Light_Conditions', 'Urban_or_Rural_Area', '1st_Road_Class', '1st_Road_Number',\n",
    "    '2nd_Road_Class', '2nd_Road_Number', 'Local_Authority_Highway', 'Junction_Detail',\n",
    "    'Junction_Control', 'Pedestrian_Crossing-Human_Control', 'Pedestrian_Crossing-Physical_Facilities',\n",
    "    'Road_Surface_Conditions', 'Special_Conditions_at_Site', 'Carriageway_Hazards',\n",
    "    'Did_Police_Officer_Attend_Scene_of_Accident', 'Local_Authority_District','LSOA_of_Accident_Location','Accident_Index'\n",
    "                       ]\n",
    "\n",
    "all_columns = numerical_columns\n",
    "\n",
    "num_cols = 3  \n",
    "num_rows = math.ceil(len(all_columns) / num_cols)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(all_columns):\n",
    "    if column in numerical_columns:\n",
    "        \n",
    "        data = main_df[column]\n",
    "        mean = data.mean()\n",
    "        median = data.median()\n",
    "        std = data.std()\n",
    "        skewness = skew(data, nan_policy='omit')\n",
    "        kurt = kurtosis(data, nan_policy='omit')\n",
    "        mode = data.mode()[0]\n",
    "        value_range = (data.min(), data.max())\n",
    "\n",
    "        sns.histplot(data=data, kde=True, ax=axes[i], color='blue')\n",
    "        axes[i].axvline(mean, color='red', linestyle='--', label=f'Mean: {mean:.2f}')\n",
    "        axes[i].axvline(median, color='green', linestyle='--', label=f'Median: {median:.2f}')\n",
    "        axes[i].set_title(f'{column}')\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        \n",
    "        stats_text = (f\"Range: {value_range}\\nMean: {mean:.2f}\\nStd: {std:.2f}\\n\"\n",
    "                      f\"Skewness: {skewness:.2f}\\nKurtosis: {kurt:.2f}\\nMode: {mode}\")\n",
    "        axes[i].text(0.95, 0.95, stats_text, transform=axes[i].transAxes, fontsize=10,\n",
    "                     verticalalignment='top', horizontalalignment='right',\n",
    "                     bbox=dict(boxstyle=\"round\", alpha=0.3))\n",
    "        axes[i].legend()\n",
    "\n",
    "    elif column in categorical_columns:\n",
    "        \n",
    "        sns.countplot(data=main_df, x=column, ax=axes[i], color='skyblue', \n",
    "                      order=main_df[column].value_counts().index)\n",
    "        axes[i].set_title(f'{column}')\n",
    "        axes[i].set_xlabel(column)\n",
    "        axes[i].set_ylabel('Count')\n",
    "\n",
    "        for p in axes[i].patches:\n",
    "            axes[i].annotate(f'{int(p.get_height())}', \n",
    "                             (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                             ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
    "                             textcoords='offset points')\n",
    "        axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "for j in range(len(all_columns), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=4, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    sns.countplot(\n",
    "        data=main_df,\n",
    "        x=column,\n",
    "        order=main_df[column].value_counts().index,\n",
    "        color='skyblue',\n",
    "        ax=axes[i]\n",
    "    )\n",
    "    axes[i].set_title(f'Distribution of {column}')\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Count')\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "    mode = main_df[column].mode()[0]\n",
    "    count = main_df[column].value_counts()[mode]\n",
    "    axes[i].annotate(f'Mode: {mode}\\nCount: {count}', \n",
    "                     xy=(0.5, 0.9), xycoords='axes fraction', \n",
    "                     ha='center', va='center', fontsize=10, \n",
    "                     bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor='black', facecolor='white'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "updated_missing_values = main_df.isnull().sum()\n",
    "print(\"Updated Missing Values Per Column:\")\n",
    "print(updated_missing_values)\n",
    "\n",
    "\n",
    "sns.heatmap(main_df.isnull(), cbar=False, cmap='viridis')\n",
    "plt.title(\"Missing Data Heatmap After Removing Rows with Missing Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_classes = {}\n",
    "\n",
    "for column in categorical_columns:\n",
    "    class_counts = main_df[column].value_counts(normalize=True) * 100\n",
    "    if class_counts.max() > 90:  \n",
    "        imbalanced_classes[column] = class_counts\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = oversampler.fit_resample(main_df.drop('Accident_Severity', axis=1),\n",
    "                                                     main_df['Accident_Severity'])\n",
    "\n",
    "\n",
    "balanced_df = X_resampled.copy()\n",
    "balanced_df['Accident_Severity'] = y_resampled\n",
    "\n",
    "print(balanced_df['Accident_Severity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['Number_of_Vehicles', 'Number_of_Casualties']\n",
    "\n",
    "for column in numerical_columns:\n",
    " \n",
    "    Q1 = main_df[column].quantile(0.25)\n",
    "    Q3 = main_df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    main_df = main_df[(main_df[column] >= lower_bound) & (main_df[column] <= upper_bound)]\n",
    "\n",
    "print(\"Shape after outlier removal:\", main_df.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(main_df[column], kde=True, color='blue')\n",
    "    plt.title(f'Distribution of {column} After Outlier Removal')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(main_df[column], orient='h', color='skyblue')\n",
    "    plt.title(f'Boxplot of {column} After Outlier Removal')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_extreme_values(df, numerical_columns):\n",
    "    for column in numerical_columns:\n",
    "        low_percentile = df[column].quantile(0.01)\n",
    "        high_percentile = df[column].quantile(0.99)\n",
    "        \n",
    "        extreme_values = df[(df[column] < low_percentile) | (df[column] > high_percentile)]\n",
    "        \n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(data=df[column], color='lightblue', showfliers=False)  # Boxplot without default outliers\n",
    "        plt.scatter(extreme_values[column], [0] * len(extreme_values), color='orange', label='Extreme Values')  # Highlight extreme values\n",
    "        plt.title(f'Boxplot of {column} with Highlighted Extreme Values')\n",
    "        plt.xlabel(column)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "numerical_columns = ['Number_of_Vehicles', 'Number_of_Casualties']\n",
    "\n",
    "plot_extreme_values(main_df, numerical_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine why,why and how each attribute should and should not be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_attributes = [\n",
    "    \"Number_of_Casualties\",\n",
    "    \"Number_of_Vehicles\",\n",
    "    \"Road_Type\",\n",
    "    \"Speed_limit\",\n",
    "    \"Light_Conditions\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"Accident_Severity\",\n",
    "    \"Weather_Conditions\",\n",
    "    \"Road_Surface_Conditions\"\n",
    "]\n",
    "\n",
    "filtered_df = main_df[selected_attributes]\n",
    "\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide dataset (Training, Test & Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = filtered_df.drop(columns=[\"Accident_Severity\"])  \n",
    "y = filtered_df[\"Accident_Severity\"]  \n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(\"Training Set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation Set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test Set:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categorical_columns_to_encode = [\n",
    "    \"Road_Type\",\n",
    "    \"Speed_limit\",\n",
    "    \"Light_Conditions\",\n",
    "    \"Accident_Severity\",\n",
    "    \"Weather_Conditions\",\n",
    "    \"Road_Surface_Conditions\"\n",
    "]\n",
    "\n",
    "final_df = pd.get_dummies(filtered_df, columns=categorical_columns_to_encode, drop_first=True)\n",
    "\n",
    "print(\"Dataset After One-Hot Encoding:\")\n",
    "print(final_df.columns.tolist)\n",
    "\n",
    "print(\"Shape after encoding:\", final_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - Descriptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=final_df, x=\"Number_of_Vehicles\", y=\"Number_of_Casualties\", alpha=0.6)\n",
    "plt.title(\"Scatter Plot: Number of Vehicles vs Number of Casualties\")\n",
    "plt.xlabel(\"Number of Vehicles\")\n",
    "plt.ylabel(\"Number of Casualties\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = final_df.columns\n",
    "\n",
    "encoded_road_type = [col for col in all_columns if 'Road_Type' in col]\n",
    "encoded_speed_limit = [col for col in all_columns if 'Speed_limit' in col]\n",
    "encoded_light_conditions = [col for col in all_columns if 'Light_Conditions' in col]\n",
    "\n",
    "print(\"Encoded Road_Type Columns:\", encoded_road_type)\n",
    "print(\"Encoded Speed_Limit Columns:\", encoded_speed_limit)\n",
    "print(\"Encoded Light_Conditions Columns:\", encoded_light_conditions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numerical_columns = ['Number_of_Vehicles', 'Number_of_Casualties']\n",
    "encoded_columns = encoded_road_type + encoded_speed_limit + encoded_light_conditions\n",
    "relevant_columns = numerical_columns + encoded_columns\n",
    "\n",
    "correlation_matrix = final_df[relevant_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix for Numerical and Encoded Categorical Attributes\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = pd.DataFrame()\n",
    "\n",
    "for road in encoded_road_type:\n",
    "    for light in encoded_light_conditions:\n",
    "        heatmap_data.loc[road, light] = \\\n",
    "            final_df[(final_df[road] == 1) & (final_df[light] == 1)][\"Number_of_Casualties\"].count()\n",
    "\n",
    "heatmap_data.index = [col.replace(\"Road_Type_\", \"Road Type \") for col in encoded_road_type]\n",
    "heatmap_data.columns = [col.replace(\"Light_Conditions_\", \"Light Conditions \") \\\n",
    "                        for col in encoded_light_conditions]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap=\"Blues\", fmt=\".0f\")\n",
    "plt.title(\"Heatmap: Road Type vs Light Conditions\")\n",
    "plt.xlabel(\"Light Conditions\")\n",
    "plt.ylabel(\"Road Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "geo_data = final_df[['Longitude', 'Latitude', 'Number_of_Casualties']].dropna()\n",
    "\n",
    "k = 5  \n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)  \n",
    "geo_data['Cluster'] = kmeans.fit_predict(geo_data[['Longitude', 'Latitude']])\n",
    "\n",
    "cluster_summary = geo_data.groupby('Cluster').agg(\n",
    "    Total_Casualties=('Number_of_Casualties', 'sum'),\n",
    "    Average_Casualties=('Number_of_Casualties', 'mean'),\n",
    "    Accident_Count=('Cluster', 'count')\n",
    ").reset_index()\n",
    "\n",
    "print(\"Cluster Summary:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(geo_data['Longitude'], geo_data['Latitude'], c=geo_data['Cluster'], cmap='viridis', s=10, alpha=0.6)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], c='red', marker='X', s=100, label='Centroids')\n",
    "\n",
    "for i, row in cluster_summary.iterrows():\n",
    "    plt.text(kmeans.cluster_centers_[i, 0], kmeans.cluster_centers_[i, 1],\n",
    "             f\"Casualties: {row['Total_Casualties']}\\nAccidents: {row['Accident_Count']}\",\n",
    "             color='black', fontsize=8, ha='center')\n",
    "\n",
    "plt.title(\"K-Means Clustering: Accident Hotspots with Casualty Information\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.colorbar(label=\"Cluster ID\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_df.columns.tolist)\n",
    "\n",
    "encoded_weather_conditions = [col for col in all_columns if 'Weather_Conditions' in col]\n",
    "encoded_road_surface_conditions = [col for col in all_columns if 'Road_Surface_Conditions' in col]\n",
    "encoded_speed_limit_conditions = [col for col in all_columns if 'Speed_limit' in col]\n",
    "encoded_light_conditions = [col for col in all_columns if 'Light_Conditions' in col]\n",
    "\n",
    "features = numerical_columns + encoded_road_type + encoded_speed_limit + encoded_light_conditions + encoded_weather_conditions + encoded_road_surface_conditions\n",
    "\n",
    "encoded_accident_severity_conditions = [col for col in all_columns if 'Accident_Severity' in col]\n",
    "\n",
    "X = final_df[features]\n",
    "y = final_df[encoded_accident_severity_conditions]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "y_train_single = y_train.idxmax(axis=1) \n",
    "y_val_single = y_val.idxmax(axis=1)\n",
    "\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight=\"balanced\", classes=y_train_single.unique(), y=y_train_single\n",
    ")\n",
    "class_weights = {cls: weight for cls, weight in zip(y_train_single.unique(), weights)}\n",
    "\n",
    "dt_model = DecisionTreeClassifier(criterion='gini', max_depth=6, random_state=42, class_weight=class_weights)\n",
    "dt_model.fit(X_train, y_train_single)\n",
    "\n",
    "y_pred_val = dt_model.predict(X_val)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val_single, y_pred_val))\n",
    "print(\"\\nClassification Report on Validation Set:\")\n",
    "print(classification_report(y_val_single, y_pred_val))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(dt_model, X_val, y_val_single, cmap=\"Blues\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP6ahOWKVA2LPOnijCFzVxt",
   "mount_file_id": "1OtK8Xq9IF6k039YHPKJFY0MgR4Rlaf88",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
